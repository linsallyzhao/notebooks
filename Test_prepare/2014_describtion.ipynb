{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1 a)  \n",
    "\n",
    "estimate mu and sigma from whole data set\n",
    "    \n",
    "find 0.05 and 0.01 quantiles\n",
    "    \n",
    "integrate min to 0.05 quantile and idvid by 0.05\n",
    "    \n",
    "    \n",
    "    t_es_quantile = stats.t.ppf(alpha_es, df = nega_t_para[0] , loc = nega_t_para[1], scale = nega_t_para[2])\n",
    "    domain_t = x_ticks[x_ticks <= t_es_quantile]\n",
    "    pdf_t = stats.t.pdf(domain_t, df = nega_t_para[0] , loc = nega_t_para[1], scale = nega_t_para[2])\n",
    "    to_integral = pdf_t * domain_t\n",
    "    t_ES[i - start_test] = integrate.trapz(to_integral, domain_t, dx = 0.01) / (1 - alpha_es)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b)\n",
    "\n",
    "count how many historical loss is lower than 95%var, 99%var, and 95%ES, 99%ES. If number higher than 5%/1% then not a good describtion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# c) \n",
    "\n",
    "Can use historical or kernel\n",
    "   \n",
    "   Historical is easier\n",
    "   \n",
    "   Use both parametric and non-parametirc. Non-parametric allow you to make less assumption\n",
    "   \n",
    "   parametric is faster to calculate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## d) \n",
    "\n",
    "input to the function should be cumsum reture or price series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def genHurst(data, q=1, maxT=19):\n",
    "    data = np.asarray(data)\n",
    "    lq = len(q)\n",
    "    H = np.zeros((maxT-4, lq))\n",
    "    k = 0;\n",
    "    \n",
    "    for Tmax in range(5, maxT+1):\n",
    "        k = k + 1\n",
    "        x = np.asarray(range(1, Tmax+1)) * 1.0\n",
    "        mcord = np.zeros((Tmax, lq))\n",
    "        for tt in range(1, Tmax+1):\n",
    "            dV = data[range(tt, len(data), tt)] - data[range(0, len(data)-tt, tt)]\n",
    "            VV = data[range(0, len(data), tt)]\n",
    "            N = len(dV) + 1\n",
    "            X = np.asarray(range(1, N+1)) * 1.0\n",
    "            Y = VV\n",
    "            mx = sum(X)/N\n",
    "            my = sum(Y)/N\n",
    "            SSxx = sum(X ** 2) - N * mx ** 2\n",
    "            SSxy = sum(X * Y) - N * mx * my\n",
    "            cc_1 = SSxy/SSxx\n",
    "            cc_2 = my - cc_1 * mx\n",
    "            ddVd = dV - cc_1\n",
    "            VVVd = VV - cc_1 * np.asarray(range(1, N+1)) - cc_2\n",
    "            for qq in range(0, len(q)):\n",
    "                mcord[tt-1, qq] = np.mean(abs(ddVd) ** (q[qq]))/np.mean(abs(VVVd) ** (q[qq]))\n",
    "        mx = np.mean(np.log(x))\n",
    "        SSxx = sum(np.log(x) ** 2) - Tmax * mx ** 2\n",
    "        for qq in range(0, len(q)):\n",
    "            my = np.mean(np.log(mcord[:, qq]))\n",
    "            SSxy = sum(np.log(x) * np.log(mcord[:, qq])) - Tmax*mx*my\n",
    "            H[k-1, qq] = SSxy/SSxx\n",
    "    \n",
    "    mH = np.mean(H, 0) / q\n",
    "    sH = np.std(H, 0) / q\n",
    "    return mcord, mH, sH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## e) \n",
    "\n",
    "Notes Part_2 Page 26, $\\alpha$ = 1 / H  \n",
    "## Which H to use? Both?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## f) \n",
    "\n",
    "resample yearly\n",
    "\n",
    "   estimate HS Var"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2 a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pandas.DataFrame.cov\n",
    "\n",
    "https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.cov.html\n",
    "\n",
    "y contains the covariance matrix of the DataFrameâ€™s time series. The covariance is normalized by N-1 (unbiased estimator).\n",
    "\n",
    "KenTau = allAssets.corr(method='kendall')\n",
    "KenTau"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b)\n",
    "\n",
    "Part 3 page 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linRegre(data):\n",
    "    betaMa = pd.DataFrame(index=logRC.columns, columns=logRC.columns)\n",
    "    ssrMa = pd.DataFrame(index=logRC.columns, columns=logRC.columns)\n",
    "    lenMa = pd.DataFrame(index=logRC.columns, columns=logRC.columns)\n",
    "    varMa = pd.DataFrame(index=logRC.columns, columns=logRC.columns)\n",
    "    for ref_col in logRC:\n",
    "        for col in logRC:\n",
    "            formu = f'{ref_col} ~ {col}'\n",
    "            model = smf.ols(formula=formu, data=logRC)\n",
    "            res = model.fit()\n",
    "            betaMa[ref_col][col] = res.params[1]\n",
    "            ssrMa[ref_col][col] = res.ssr\n",
    "            lenMa[ref_col][col] = len(logRC[col].dropna())\n",
    "            varMa[ref_col][col] = np.var(logRC[ref_Lcol])\n",
    "        \n",
    "1 - ((ssrMa / lenMa) / varMa) - corrcoeff ** 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## c)\n",
    "\n",
    "Write a test (permutation, bootstrap, or moving window)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## d)\n",
    "max sharp-ratio target, constraint?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## e)\n",
    "\n",
    "I can calculate Kendall and Spearman but how to conclude?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
